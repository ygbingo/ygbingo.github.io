<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>数据挖掘面试题 - Bingo&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="YG.Bingo" /><meta name="description" content="什么是数据挖掘(Data Mining) 数据挖掘是指从大量数据中提取或挖掘知识。换句话说，数据挖掘是发现大量复杂数据以发现有用模式的科学、艺术和技术。 数据" /><meta name="keywords" content="Bingo, blog" />






<meta name="generator" content="Hugo 0.122.0 with theme even" />


<link rel="canonical" href="https://ygbingo.github.io/post/2024-03-04-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E9%9D%A2%E8%AF%95%E9%A2%98/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="数据挖掘面试题" />
<meta property="og:description" content="什么是数据挖掘(Data Mining) 数据挖掘是指从大量数据中提取或挖掘知识。换句话说，数据挖掘是发现大量复杂数据以发现有用模式的科学、艺术和技术。 数据" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ygbingo.github.io/post/2024-03-04-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E9%9D%A2%E8%AF%95%E9%A2%98/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-03-04T10:31:23+08:00" />
<meta property="article:modified_time" content="2024-03-04T10:31:23+08:00" />

<meta itemprop="name" content="数据挖掘面试题">
<meta itemprop="description" content="什么是数据挖掘(Data Mining) 数据挖掘是指从大量数据中提取或挖掘知识。换句话说，数据挖掘是发现大量复杂数据以发现有用模式的科学、艺术和技术。 数据"><meta itemprop="datePublished" content="2024-03-04T10:31:23+08:00" />
<meta itemprop="dateModified" content="2024-03-04T10:31:23+08:00" />
<meta itemprop="wordCount" content="8048">
<meta itemprop="keywords" content="interview,data mining," /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="数据挖掘面试题"/>
<meta name="twitter:description" content="什么是数据挖掘(Data Mining) 数据挖掘是指从大量数据中提取或挖掘知识。换句话说，数据挖掘是发现大量复杂数据以发现有用模式的科学、艺术和技术。 数据"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Bingo</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">文章</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Bingo</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">文章</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">数据挖掘面试题</h1>

      <div class="post-meta">
        <span class="post-time"> 2024-03-04 </span>
        
          <span class="more-meta"> 约 8048 字 </span>
          <span class="more-meta"> 预计阅读 17 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#什么是数据挖掘data-mining">什么是数据挖掘(Data Mining)</a></li>
    <li><a href="#数据挖掘有哪些任务">数据挖掘有哪些任务</a></li>
    <li><a href="#数据挖掘的步骤有哪些">数据挖掘的步骤有哪些</a></li>
    <li><a href="#解释一下知识发现kdd-knowledge-discovery-from-data的流程">解释一下知识发现(KDD: Knowledge Discovery from Data)的流程</a></li>
    <li><a href="#什么是分类classification">什么是分类(Classification)</a></li>
    <li><a href="#解释一下evolution和deviation">解释一下evolution和deviation</a></li>
    <li><a href="#什么是预测prediction">什么是预测(Prediction)</a></li>
    <li><a href="#什么是决策树">什么是决策树</a></li>
    <li><a href="#决策树有什么优势">决策树有什么优势</a></li>
    <li><a href="#解释一下数据挖掘中的贝叶斯分类">解释一下数据挖掘中的贝叶斯分类</a></li>
    <li><a href="#阐述一下模糊逻辑fuzzy-logic的重要性">阐述一下模糊逻辑(fuzzy logic)的重要性</a></li>
    <li><a href="#什么是神经网络">什么是神经网络</a></li>
    <li><a href="#神经网络如何进行反向传播">神经网络如何进行反向传播</a></li>
    <li><a href="#什么是遗传算法genetic-algorithm">什么是遗传算法(Genetic algorithm)</a></li>
    <li><a href="#什么是分类准确度">什么是分类准确度</a></li>
    <li><a href="#什么是聚类">什么是聚类</a></li>
    <li><a href="#分类和聚类的区别是什么">分类和聚类的区别是什么</a></li>
    <li><a href="#解释数据挖掘中的关联算法">解释数据挖掘中的关联算法</a></li>
    <li><a href="#解释如何使用-sql-server-数据挖掘中包含的数据挖掘算法">解释如何使用 SQL Server 数据挖掘中包含的数据挖掘算法</a></li>
    <li><a href="#解释一下过拟合over-fitting">解释一下过拟合(over fitting)</a></li>
    <li><a href="#解释一下决策树剪枝tree-pruning">解释一下决策树剪枝(Tree Pruning)</a></li>
    <li><a href="#什么是sting">什么是Sting</a></li>
    <li><a href="#解释一下k-means算法">解释一下K-Means算法</a></li>
    <li><a href="#解释一下精确率和召回率">解释一下精确率和召回率</a></li>
    <li><a href="#t检验和z检验的理想情况是什么">t检验和z检验的理想情况是什么</a></li>
    <li><a href="#如何进行异常值检测">如何进行异常值检测</a></li>
    <li><a href="#解释一下分类器中的预剪枝prepruning和后剪枝postpruning">解释一下分类器中的预剪枝Prepruning和后剪枝Postpruning</a></li>
    <li><a href="#如何处理异常数据">如何处理异常数据</a></li>
    <li><a href="#pca和fa的区别">PCA和FA的区别</a></li>
    <li><a href="#数据挖掘和数据分析的区别">数据挖掘和数据分析的区别</a></li>
    <li><a href="#方差和协方差的区别是什么">方差和协方差的区别是什么</a></li>
    <li><a href="#假设检验有哪些">假设检验有哪些</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="什么是数据挖掘data-mining">什么是数据挖掘(Data Mining)</h1>
<p>数据挖掘是指从大量数据中提取或挖掘知识。换句话说，数据挖掘是发现大量复杂数据以发现有用模式的科学、艺术和技术。</p>
<h1 id="数据挖掘有哪些任务">数据挖掘有哪些任务</h1>
<ul>
<li>Classification 分类</li>
<li>Clustering 聚类</li>
<li>Association Rule Discovery 关联规则发现</li>
<li>Sequential Pattern Discovery 顺序模式发现</li>
<li>Regression 回归</li>
<li>Deviation Detection 偏差检测</li>
</ul>
<h1 id="数据挖掘的步骤有哪些">数据挖掘的步骤有哪些</h1>
<ol>
<li>
<p>业务理解：从业务角度理解项目目标，数据挖掘问题定义。</p>
</li>
<li>
<p>数据理解：初始数据收集并理解它。</p>
</li>
<li>
<p>数据准备：根据原始数据构建最终数据集。</p>
</li>
<li>
<p>建模：选择并应用数据建模技术。</p>
</li>
<li>
<p>评估：评估模型，决定进一步部署。</p>
</li>
<li>
<p>部署：创建报告，根据新见解采取行动。</p>
</li>
<li>
<p>Business understanding: Understanding projects objectives from a business perspective, data mining problem definition.</p>
</li>
<li>
<p>Data understanding: Initial data collection and understand it.</p>
</li>
<li>
<p>Data preparation: Constructing the final data set from raw data.</p>
</li>
<li>
<p>Modeling: Select and apply data modeling techniques.</p>
</li>
<li>
<p>Evaluation: Evaluate model, decide on further deployment.</p>
</li>
<li>
<p>Deployment: Create a report, carry out actions based on new insights.</p>
</li>
</ol>
<h1 id="解释一下知识发现kdd-knowledge-discovery-from-data的流程">解释一下知识发现(KDD: Knowledge Discovery from Data)的流程</h1>
<p>数据挖掘被视为另一个常用术语“数据知识发现”或 KDD 的同义词。在其他人看来，数据挖掘只是知识发现过程中的一个重要步骤，其中应用智能方法来提取数据模式。
从数据中发现知识包括以下步骤：</p>
<ol>
<li>数据清理（去除噪音或不相关数据）。</li>
<li>数据集成（可以组合多个数据源）。</li>
<li>数据选择（从数据库检索与分析任务相关的数据）。</li>
<li>数据转换（例如，通过执行汇总或聚合功能将数据转换或合并为适合挖掘的形式）。</li>
<li>数据挖掘（应用智能方法提取数据模式的重要过程）。</li>
<li>模式评估（根据一些兴趣度度量来识别代表知识的令人着迷的模式）。</li>
<li>知识表示（知识表示和可视化技术用于将挖掘的知识呈现给用户）。</li>
</ol>
<p>Data mining treat as a synonym for another popularly used term, Knowledge Discovery from Data, or KDD. In others view data mining as simply an essential step in the process of knowledge discovery, in which intelligent methods are applied in order to extract data patterns.</p>
<p>Knowledge discovery from data consists of the following steps:</p>
<p>Data cleaning (to remove noise or irrelevant data).
Data integration (where multiple data sources may be combined).
Data selection (where data relevant to the analysis task are retrieved from the database).
Data transformation (where data are transmuted or consolidated into forms appropriate for mining by performing summary or aggregation functions, for sample).
Data mining (an important process where intelligent methods are applied in order to extract data patterns).
Pattern evaluation (to identify the fascinating patterns representing knowledge based on some interestingness measures).
Knowledge presentation (where knowledge representation and visualization techniques are used to present the mined knowledge to the user).</p>
<h1 id="什么是分类classification">什么是分类(Classification)</h1>
<p>分类是寻找一组描述和区分数据类或概念的模型（或函数）的过程，目的是能够使用模型来预测类标签未知的对象的类。分类可用于预测数据项的类标签。然而，在许多应用程序中，人们可能喜欢计算一些缺失或不可用的数据值而不是类标签。</p>
<p>Classification is the processing of finding a set of models (or functions) that describe and distinguish data classes or concepts, for the purpose of being able to use the model to predict the class of objects whose class label is unknown. Classification can be used for predicting the class label of data items. However, in many applications, one may like to calculate some missing or unavailable data values rather than class labels.</p>
<h1 id="解释一下evolution和deviation">解释一下evolution和deviation</h1>
<p>数据演化分析描述并建模了行为随时间变化的对象的规律或趋势。尽管这可能涉及时间相关数据的区分、关联、分类、表征或聚类，但此类分析的独特特征涉及时间序列数据分析、周期性模式匹配和基于相似性的数据分析。</p>
<p>Data evolution analysis describes and models regularities or trends for objects whose behavior variations over time. Although this may involve discrimination, association, classification, characterization, or clustering of time-related data, distinct features of such an analysis involve time-series data analysis, periodicity pattern matching, and similarity-based data analysis.</p>
<p>在分析与时间相关的数据时，通常不仅需要对数据的总体演化趋势进行建模，还需要识别随时间推移发生的数据偏差。偏差是测量值与相应参考值（例如先前值或标准值）之间的差异。执行偏差分析的数据挖掘系统在检测到一组偏差后，可以执行以下操作：描述偏差的特征，尝试描述偏差背后的原因，并建议采取措施将偏差值恢复到预期值。</p>
<p>In the analysis of time-related data, it is often required not only to model the general evolutionary trend of the data but also to identify data deviations that occur over time. Deviations are differences between measured values and corresponding references such as previous values or normative values. A data mining system performing deviation analysis, upon the detection of a set of deviations, may do the following: describe the characteristics of the deviations, try to describe the reason behindhand them, and suggest actions to bring the deviated values back to their expected values.</p>
<h1 id="什么是预测prediction">什么是预测(Prediction)</h1>
<p>预测可以被视为构建和使用模型来评估未标记对象的类别，或者测量给定对象可能具有的属性的值或值范围。在这种解释中，分类和回归是预测问题的两种主要类型，其中分类用于预测离散值或名义值，而回归用于预测连续值或有序值。</p>
<p>Prediction can be viewed as the construction and use of a model to assess the class of an unlabeled object, or to measure the value or value ranges of an attribute that a given object is likely to have. In this interpretation, classification and regression are the two major types of prediction problems where classification is used to predict discrete or nominal values, while regression is used to predict incessant or ordered values.</p>
<h1 id="什么是决策树">什么是决策树</h1>
<p>决策树是一种类似流程图的树结构，其中每个内部节点（非叶节点）表示对属性的测试，每个分支代表测试的结果，每个叶节点（或终端节点）保存一个类标签。树的最顶层节点是根节点。</p>
<p>决策树是一种分类方案，它从给定的数据集中生成一棵树和一组规则，表示不同类别的模型。可用于开发分类方法的记录集通常分为两个不相交的子集，即训练集和测试集。前者用于生成分类器，后者用于衡量分类器的准确性。分类器的准确性由正确分类的测试示例的百分比决定。</p>
<p>在决策树分类器中，我们将记录的属性分为两种不同的类型。域为数值的属性称为数值属性，域非数值的属性称为分类属性。有一个称为类标签的显着属性。分类的目标是建立一个简洁的模型，可用于预测类别标签未知的记录的类别。决策树可以简单地转换为分类规则。</p>
<p>A Decision tree is a flow chart-like tree structure, where each internal node (non-leaf node) denotes a test on an attribute, each branch represents an outcome of the test and each leaf node (or terminal node) holds a class label. The topmost node of a tree is the root node.</p>
<p>A Decision tree is a classification scheme that generates a tree and a set of rules, representing the model of different classes, from a given data set. The set of records available for developing classification methods is generally divided into two disjoint subsets namely a training set and a test set. The former is used for originating the classifier while the latter is used to measure the accuracy of the classifier. The accuracy of the classifier is determined by the percentage of the test examples that are correctly classified.</p>
<p>In the decision tree classifier, we categorize the attributes of the records into two different types. Attributes whose domain is numerical are called the numerical attributes and the attributes whose domain is not numerical are called categorical attributes. There is one distinguished attribute called a class label. The goal of classification is to build a concise model that can be used to predict the class of the records whose class label is unknown. Decision trees can simply be converted to classification rules.</p>
<h1 id="决策树有什么优势">决策树有什么优势</h1>
<ul>
<li>决策树能够产生可理解的规则。</li>
<li>它们能够处理数字和分类属性。</li>
<li>它们很容易理解。</li>
<li>一旦建立了决策树模型，对测试记录进行分类的速度就会非常快。</li>
<li>决策树描述足够丰富，可以表示任何离散值分类器。</li>
<li>决策树可以处理可能有错误的数据集。</li>
<li>决策树可以处理可能存在缺失值的数据集。</li>
<li>它们不需要任何事先的假设。决策树是不言自明的，并且在压缩后也很容易遵循。也就是说，如果决策树具有合理的叶子数量，那么非专业用户也可以掌握。此外，由于决策树可以转换为一组规则，因此这种表示形式被认为是可以理解的。</li>
</ul>
<p>Decision trees are able to produce understandable rules.
They are able to handle both numerical and categorical attributes.
They are easy to understand.
Once a decision tree model has been built, classifying a test record is extremely fast.
Decision tree depiction is rich enough to represent any discrete value classifier.
Decision trees can handle datasets that may have errors.
Decision trees can deal with handle datasets that may have missing values.
They do not require any prior assumptions.  Decision trees are self-explanatory and when compacted they are also easy to follow. That is to say, if the decision tree has a reasonable number of leaves it can be grasped by non-professional users. Furthermore, since decision trees can be converted to a set of rules, this sort of representation is considered comprehensible.</p>
<h1 id="解释一下数据挖掘中的贝叶斯分类">解释一下数据挖掘中的贝叶斯分类</h1>
<p>贝叶斯分类器是一种统计分类器。它们可以预测类别成员概率，例如给定样本属于特定类别的概率。贝叶斯分类是根据贝叶斯定理创建的。简单的贝叶斯分类器被称为朴素贝叶斯分类器，其性能可与决策树和神经网络分类器相媲美。贝叶斯分类器在应用于大型数据库时也显示出较高的准确性和速度。</p>
<p>A Bayesian classifier is a statistical classifier. They can predict class membership probabilities, for instance, the probability that a given sample belongs to a particular class. Bayesian classification is created on the Bayes theorem. A simple Bayesian classifier is known as the naive Bayesian classifier to be comparable in performance with decision trees and neural network classifiers. Bayesian classifiers have also displayed high accuracy and speed when applied to large databases.</p>
<h1 id="阐述一下模糊逻辑fuzzy-logic的重要性">阐述一下模糊逻辑(fuzzy logic)的重要性</h1>
<p>基于规则的分类系统的缺点是它们涉及连续属性的精确值。模糊逻辑对于执行分类的数据挖掘系统很有用。它提供了在高抽象级别上工作的好处。一般来说，模糊逻辑在基于规则的系统中的使用涉及以下内容：</p>
<ul>
<li>属性值更改为模糊值。</li>
<li>对于给定的新样本，可以应用多个模糊规则。每条适用的规则都会为类别中的成员资格投票。通常，对每个预测类别的真值进行求和。</li>
<li>将上面获得的总和组合成系统返回的值。该过程可以通过用真值和对每个类别进行加权并乘以每个类别的平均真值来完成。所涉及的计算可能更复杂，具体取决于模糊隶属图的难度。</li>
</ul>
<p>Rule-based systems for classification have the disadvantage that they involve exact values for continuous attributes. Fuzzy logic is useful for data mining systems performing classification. It provides the benefit of working at a high level of abstraction. In general, the usage of fuzzy logic in rule-based systems involves the following:</p>
<ul>
<li>Attribute values are changed to fuzzy values.</li>
<li>For a given new sample, more than one fuzzy rule may apply. Every applicable rule contributes a vote for membership in the categories. Typically, the truth values for each projected category are summed.</li>
<li>The sums obtained above are combined into a value that is returned by the system. This process may be done by weighting each category by its truth sum and multiplying by the mean truth value of each category. The calculations involved may be more complex, depending on the difficulty of the fuzzy membership graphs.</li>
</ul>
<h1 id="什么是神经网络">什么是神经网络</h1>
<p>神经网络是一组连接的输入/输出单元，其中每个连接都有一个与其关联的权重。在知识阶段，网络通过调整权重来获得能够预测输入样本的正确类别标签的能力。由于单元之间的连接，神经网络学习也被称为联结主义学习。神经网络需要较长的训练时间，因此更适合可行的应用。它们需要许多通常最好凭经验确定的参数，例如网络拓扑或“结构”。神经网络因其可解释性差而受到批评，因为人类很难理解学习权重背后的象征意义。这些特征首先使得神经网络不太适合数据挖掘。
然而，神经网络的优点包括对噪声数据的高容忍度以及对未经训练的模式进行分类的能力。此外，还新开发了几种算法，用于从经过训练的神经网络中提取规则。这些问题有助于神经网络在数据挖掘中分类的有用性。最流行的神经网络算法是 20 世纪 80 年代提出的反向传播算法</p>
<p>A neural network is a set of connected input/output units where each connection has a weight associated with it. During the knowledge phase, the network acquires by adjusting the weights to be able to predict the correct class label of the input samples. Neural network learning is also denoted as connectionist learning due to the connections between units. Neural networks involve long training times and are therefore more appropriate for applications where this is feasible. They require a number of parameters that are typically best determined empirically, such as the network topology or “structure”. Neural networks have been criticized for their poor interpretability since it is difficult for humans to take the symbolic meaning behind the learned weights. These features firstly made neural networks less desirable for data mining.</p>
<p>The advantages of neural networks, however, contain their high tolerance to noisy data as well as their ability to classify patterns on which they have not been trained. In addition, several algorithms have newly been developed for the extraction of rules from trained neural networks. These issues contribute to the usefulness of neural networks for classification in data mining. The most popular neural network algorithm is the backpropagation algorithm, proposed in the 1980s</p>
<h1 id="神经网络如何进行反向传播">神经网络如何进行反向传播</h1>
<p>反向传播通过迭代处理一组训练样本，将网络对每个样本的估计与实际已知的类标签进行比较来进行学习。对于每个训练样本，修改权重以最小化网络预测与实际类别之间的均方误差。这些变化是在&quot;backward&quot;方向进行的，即从输出层，通过每个隐藏层一直到第一个隐藏层（因此称为反向传播）。虽然不能保证，但一般来说，权重最终会收敛，知识过程就会停止。</p>
<p>A Backpropagation learns by iteratively processing a set of training samples, comparing the network’s estimate for each sample with the actual known class label. For each training sample, weights are modified to minimize the mean squared error between the network’s prediction and the actual class. These changes are made in the “backward” direction, i.e., from the output layer, through each concealed layer down to the first hidden layer (hence the name backpropagation). Although it is not guaranteed, in general, the weights will finally converge, and the knowledge process stops.</p>
<h1 id="什么是遗传算法genetic-algorithm">什么是遗传算法(Genetic algorithm)</h1>
<p>遗传算法是进化计算的一部分，进化计算是人工智能快速发展的领域。遗传算法的灵感来自达尔文的进化论。这里遗传算法解决的问题的解决方案是进化的。在遗传算法中，一组字符串（称为染色体或基因型）将候选解决方案（称为个体、生物或表型）编码为优化问题，并朝着更好的解决方案进化。传统上，解决方案以二进制字符串的形式表示，由 0 和 1 组成，同样也可以应用其他编码方案。</p>
<p>Genetic algorithm is a part of evolutionary computing which is a rapidly growing area of artificial intelligence. The genetic algorithm is inspired by Darwin’s theory about evolution. Here the solution to a problem solved by the genetic algorithm is evolved. In a genetic algorithm, a population of strings (called chromosomes or the genotype of the gen me), which encode candidate solutions (called individuals, creatures, or phenotypes) to an optimization problem, is evolved toward better solutions. Traditionally, solutions are represented in the form of binary strings, composed of 0s and 1s, the same way other encoding schemes can also be applied.</p>
<h1 id="什么是分类准确度">什么是分类准确度</h1>
<p>分类准确度或分类器的准确度由测试数据集示例被正确分类的百分比决定。分类树的分类精度=（1-泛化误差）。</p>
<p>Classification accuracy or accuracy of the classifier is determined by the percentage of the test data set examples that are correctly classified. The classification accuracy of a classification tree = (1 – Generalization error).</p>
<h1 id="什么是聚类">什么是聚类</h1>
<p>聚类是将总体或数据点划分为多个组的任务，使得同一组中的数据点与同一组中的其他数据点更相似，而与其他组中的数据点不相似。它基本上是基于对象之间的相似性和相异性的对象的集合。</p>
<p>Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group and dissimilar to the data points in other groups. It is basically a collection of objects on the basis of similarity and dissimilarity between them.</p>
<h1 id="分类和聚类的区别是什么">分类和聚类的区别是什么</h1>
<ul>
<li>
<p>分类</p>
<ul>
<li>Used for supervised need learning</li>
<li>Process of classifying the input instances based on their corresponding class labels</li>
<li>It has labels so there is a need for training and testing data set for verifying the model created</li>
<li>More complex as compared to clustering</li>
<li>Logistic regression, Naive Bayes classifier, Support vector machines, etc.</li>
</ul>
</li>
<li>
<p>聚类</p>
<ul>
<li>Used for unsupervised learning</li>
<li>Grouping the instances based on their similarity without the help of class labels</li>
<li>There is no need for training and testing dataset</li>
<li>Less complex as compared to classification</li>
<li>k-means clustering algorithm, Fuzzy c-means clustering algorithm, Gaussian (EM) clustering algorithm etc.</li>
</ul>
</li>
</ul>
<h1 id="解释数据挖掘中的关联算法">解释数据挖掘中的关联算法</h1>
<p>关联分析是发现关联规则，显示在给定数据集中经常一起出现的属性值条件。关联分析广泛用于市场篮子或交易数据分析。关联规则挖掘是数据挖掘研究中一个重要且异常活跃的领域。一种基于关联的分类方法称为关联分类，由两个步骤组成。在主要步骤中，使用称为 Apriori 的标准关联规则挖掘算法的修改版本生成关联指令。第二步根据发现的关联规则构造分类器。</p>
<p>Association analysis is the finding of association rules showing attribute-value conditions that occur frequently together in a given set of data. Association analysis is widely used for a market basket or transaction data analysis. Association rule mining is a significant and exceptionally dynamic area of data mining research. One method of association-based classification, called associative classification, consists of two steps. In the main step, association instructions are generated using a modified version of the standard association rule mining algorithm known as Apriori. The second step constructs a classifier based on the association rules discovered.</p>
<h1 id="解释如何使用-sql-server-数据挖掘中包含的数据挖掘算法">解释如何使用 SQL Server 数据挖掘中包含的数据挖掘算法</h1>
<p>SQL Server 数据挖掘为 Office 2007 提供了数据挖掘加载项，允许查找信息的模式和关系。这有助于改进分析。名为 Excel 数据挖掘客户端的插件用于最初准备信息、创建模型、管理、分析结果。</p>
<p>SQL Server data mining offers Data Mining Add-ins for Office 2007 that permits finding the patterns and relationships of the information. This helps in an improved analysis. The Add-in called a Data Mining Client for Excel is utilized to initially prepare information, create models, manage, analyze, results.</p>
<h1 id="解释一下过拟合over-fitting">解释一下过拟合(over fitting)</h1>
<p>过拟合的概念在数据挖掘中非常重要。它是指归纳算法生成的分类器完全适合训练数据，但失去了泛化到训练期间未呈现的实例的能力的情况。换句话说，分类器只是记住训练实例，而不是学习。在决策树中，当树相对于可用训练数据量具有太多节点时，通常会发生过度拟合。通过增加节点数量，训练误差通常会降低，而在某些时候泛化误差会变得更糟。当训练数据中存在噪声或训练数据集数量较多时，完全构建的树的误差为零，而真实误差可能更大，过度拟合可能会导致困难。</p>
<p>过拟合决策树有很多缺点：</p>
<ul>
<li>过度拟合的模型是不正确的。</li>
<li>过度拟合的决策树需要更多的空间和更多的计算资源。</li>
<li>他们需要收集不必要的特征。</li>
</ul>
<p>The concept of over-fitting is very important in data mining. It refers to the situation in which the induction algorithm generates a classifier that perfectly fits the training data but has lost the capability of generalizing to instances not presented during training. In other words, instead of learning, the classifier just memorizes the training instances. In the decision trees over fitting usually occurs when the tree has too many nodes relative to the amount of training data available. By increasing the number of nodes, the training error usually decreases while at some point the generalization error becomes worse. The  Over-fitting can lead to difficulties when there is noise in the training data or when the number of the training datasets, the error of the fully built tree is zero, while the true error is likely to be bigger.</p>
<p>There are many disadvantages of an over-fitted decision tree:</p>
<ul>
<li>Over-fitted models are incorrect.</li>
<li>Over-fitted decision trees require more space and more computational resources.</li>
<li>They require the collection of unnecessary features.</li>
</ul>
<h1 id="解释一下决策树剪枝tree-pruning">解释一下决策树剪枝(Tree Pruning)</h1>
<p>构建决策树时，许多分支将反映训练数据中由于噪声或异常值而出现的异常情况。树修剪方法解决了数据过度拟合的问题。所以树剪枝是一种消除过度拟合问题的技术。此类方法通常使用统计测量来删除最不可靠的分支，通常会导致更快的分类并提高树正确分类独立测试数据的能力。剪枝阶段消除一些较低的分支和节点以提高其性能。处理修剪后的树以提高可理解性。</p>
<p>When a decision tree is built, many of the branches will reflect anomalies in the training data due to noise or outliers. Tree pruning methods address this problem of over-fitting the data.  So the tree pruning is a technique that removes the overfitting problem. Such methods typically use statistical measures to remove the least reliable branches, generally resulting in faster classification and an improvement in the ability of the tree to correctly classify independent test data. The pruning phase eliminates some of the lower branches and nodes to improve their performance. Processing the pruned tree to improve understandability.</p>
<h1 id="什么是sting">什么是Sting</h1>
<p>统计信息网格称为STING；它是一种基于网格的多分辨率聚类策略。在STING策略中，每一项都包含在矩形单元中，这些单元保持不同程度的分辨率，并且这些级别以层次结构组织。</p>
<h1 id="解释一下k-means算法">解释一下K-Means算法</h1>
<p>K-means聚类算法——它是解决聚类问题的最简单的无监督学习算法。 K-means 算法将 n 个观测值划分为 k 个簇，其中每个观测值都属于该簇，并以最接近的均值作为该簇的原型。</p>
<p>K-means clustering algorithm – It is the simplest unsupervised learning algorithm that solves clustering problems. K-means algorithm partition n observations into k clusters where each observation belongs to the cluster with the nearest mean serving as a prototype of the cluster.</p>
<h1 id="解释一下精确率和召回率">解释一下精确率和召回率</h1>
<p>精度是n分类机制中最常用的误差度量。其范围是从 0 到 1，其中 1 代表 100%。
召回率可以定义为我们模型中实际阳性的数量，其类标签为“阳性（真阳性）”。
召回率和真阳性率完全一致。这是它的公式：
召回率=（真阳性）/（真阳性+假阴性）</p>
<p>Precision is the most commonly used error metric in the n classification mechanism. Its range is from 0 to 1, where 1 represents 100%.</p>
<p>Recall can be defined as the number of the Actual Positives in our model which has a class label as Positive (True Positive)”. Recall and the true positive rate is totally identical. Here’s the formula for it:</p>
<p>Recall = (True positive)/(True positive + False negative)</p>
<h1 id="t检验和z检验的理想情况是什么">t检验和z检验的理想情况是什么</h1>
<p>标准做法是，当示例大小低于 30 个属性时，使用 t 检验，而当示例大小大体超过 30 个时，则使用 z 检验。</p>
<p>It is a standard practice that a t-test is utilized when there is an example size under 30 attributes and the z-test is viewed as when the example size exceeds 30 by and large.</p>
<h1 id="如何进行异常值检测">如何进行异常值检测</h1>
<p>可以使用多种方法来区分异常值，但最常用的两种技术如下：</p>
<ul>
<li>标准差策略：在这里，如果该值低于或高于平均值的三个标准差，则该值被视为异常值。</li>
<li>箱线图技术：此处，如果某个值小于或高于四分位距 (IQR) 的 1.5 倍，则该值被视为异常值</li>
</ul>
<p>Numerous approaches can be utilized for distinguishing outliers anomalies, but the two most generally utilized techniques are as per the following:</p>
<ul>
<li>Standard deviation strategy: Here, the value is considered as an outlier if the value is lower or higher than three standard deviations from the mean value.</li>
<li>Box plot technique: Here, a value is viewed as an outlier if it is lesser or higher than 1.5 times the interquartile range (IQR)</li>
</ul>
<h1 id="解释一下分类器中的预剪枝prepruning和后剪枝postpruning">解释一下分类器中的预剪枝Prepruning和后剪枝Postpruning</h1>
<p><strong>预剪枝</strong>：在预剪枝方法中，通过提前停止其构造来“剪枝”树（例如，通过决定不再进一步分割或划分给定节点处的训练样本子集）。停止后，节点变成叶子。叶子可以保存子集样本中最常见的类，或者这些样本的概率分布。构建树时，可以使用统计显着性、信息增益等度量来评估分割的优劣。如果在节点处对样本进行划分将导致划分低于预先指定的阈值，则停止对给定子集的进一步划分。然而，选择合适的阈值存在问题。高阈值可能会导致树过于简化，而低阈值可能会导致简化程度非常低。</p>
<p><strong>后修剪</strong>：后修剪方法从“完全生长”的树上移除树枝。通过删除其分支来修剪树节点。成本复杂度剪枝算法是后剪枝方法的一个示例。修剪后的节点成为叶子，并用其先前分支中最常见的类进行标记。对于树中的每个非叶节点，该算法计算修剪该节点处的子树时会发生的预期错误率。接下来，使用每个分支的错误率计算如果节点未被修剪时发生的可预测错误率，并根据每个分支的观测值比例进行加权汇总。如果修剪节点导致可能的错误率更大，则保留子树。否则，就会被修剪。生成一组逐步修剪的树后，使用独立的测试集来估计每棵树的准确性。优先选择最小化预期错误率的决策树。</p>
<p>Prepruning: In the prepruning approach, a tree is “pruned” by halting its construction early (e.g., by deciding not to further split or partition the subset of training samples at a given node). Upon halting, the node becomes a leaf. The leaf may hold the most frequent class among the subset samples, or the probability distribution of those samples. When constructing a tree, measures such as statistical significance, information gain, etc., can be used to assess the goodness of a split. If partitioning the samples at a node would result in a split that falls below a pre-specified threshold, then further partitioning of the given subset is halted. There are problems, however, in choosing a proper threshold. High thresholds could result in oversimplified trees, while low thresholds could result in very little simplification.</p>
<p>Postpruning: The postpruning approach removes branches from a “fully grown” tree. A tree node is pruned by removing its branches. The cost complexity pruning algorithm is an example of the post pruning approach. The pruned node becomes a leaf and is labeled by the most frequent class among its former branches. For every non-leaf node in the tree, the algorithm calculates the expected error rate that would occur if the subtree at that node were pruned. Next, the predictable error rate occurring if the node were not pruned is calculated using the error rates for each branch, collective by weighting according to the proportion of observations along each branch. If pruning the node leads to a greater probable error rate, then the subtree is reserved. Otherwise, it is pruned. After generating a set of progressively pruned trees, an independent test set is used to estimate the accuracy of each tree. The decision tree that minimizes the expected error rate is preferred.</p>
<h1 id="如何处理异常数据">如何处理异常数据</h1>
<p>如果数据集中存在任何不一致或不确定性，用户可以继续使用任何随附的技术： 创建验证报告，其中包含有关对话中数据的见解 升级与经验丰富的数据分析师非常相似的内容以查看它并接受呼叫 用比较大量的最新数据信息替换无效信息 一起使用多种方法来发现缺失值，并在必要时使用近似估计。</p>
<h1 id="pca和fa的区别">PCA和FA的区别</h1>
<p>在众多差异中，PCA 和 FA 之间的显着差异在于，因子分析用于确定和处理变量之间的方差，但 PCA 的重点是解释当前段或变量之间的协方差。</p>
<p>Among numerous differences, the significant difference between PCA and FA is that factor analysis is utilized to determine and work with the variance between variables, but the point of PCA is to explain the covariance between the current segments or variables.</p>
<h1 id="数据挖掘和数据分析的区别">数据挖掘和数据分析的区别</h1>
<ul>
<li>
<p>数据挖掘</p>
<ul>
<li>用于感知存储数据中的设计。</li>
<li>挖掘是在干净且有据可查的情况下进行的。</li>
<li>从数据挖掘中提取的结果难以解释。</li>
<li>Used to perceive designs in data stored.</li>
<li>Mining is performed on clean and well-documented.</li>
<li>Results extracted from data mining are difficult to interpret.</li>
</ul>
</li>
<li>
<p>数据分析</p>
<ul>
<li>用于以重要的方式排列和组合原始信息。</li>
<li>信息分析包括数据清理。因此，信息无法以有据可查的格式提供。</li>
<li>从信息分析中提取的结果并不难解释。</li>
<li>Used to arrange and put together raw information in a significant manner.</li>
<li>The analysis of information includes Data Cleaning.  So, information is not available in a well-documented format.</li>
<li>Results extracted from information analysis are not difficult to interpret.</li>
</ul>
</li>
</ul>
<h1 id="方差和协方差的区别是什么">方差和协方差的区别是什么</h1>
<p>方差和协方差是统计领域中经常出现的两个数学术语。方差从根本上处理如何根据均值分隔数字。协方差是指两个随机/不规则因素如何一起变化。这本质上用于计算变量之间的相关性。</p>
<p>Variance and Covariance are two mathematical terms that are frequently in the Statistics field. Variance fundamentally processes how separated numbers are according to the mean. Covariance refers to how two random/irregular factors will change together. This is essentially used to compute the correlation between variables.</p>
<h1 id="假设检验有哪些">假设检验有哪些</h1>
<ul>
<li>
<p>T 检验：当标准差未知且样本量接近小时，使用 T 检验。</p>
</li>
<li>
<p>卡方独立性检验：这些检验用于发现总体样本中所有分类变量之间关联的显着性。</p>
</li>
<li>
<p>方差分析 (ANOVA)：这种类型的假设检验用于检查不同聚类中方法之间的对比。该检验与 T 检验相比，可用于多个组。</p>
</li>
<li>
<p>T-test: A T-test is utilized when the standard deviation is unknown and the sample size is nearly small.</p>
</li>
<li>
<p>Chi-Square Test for Independence: These tests are utilized to discover the significance of the association between all categorical variables in the population sample.</p>
</li>
<li>
<p>Analysis of Variance (ANOVA): This type of hypothesis testing is utilized to examine contrasts between the methods in different clusters. This test is utilized comparatively to a T-test but, is utilized for multiple groups.</p>
</li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">YG.Bingo</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2024-03-04
        
    </span>
  </p>
  
  
</div>
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">赞助我一杯咖啡吧！</label>
  <div class="qr-code">
    
    <label class="qr-code-image" for="reward">
        <img class="image" src="https://ygbingo-1257417561.cos.ap-shanghai.myqcloud.com/imgs/54ffe4b4-24da-4c37-8909-4c5da6ae2313.jpg">
        <span>微信打赏</span>
      </label>
    
  </div>
</div><footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/interview/">interview</a>
          <a href="/tags/data-mining/">data mining</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2024-05-14-windows11%E5%AE%89%E8%A3%85%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%A1%86%E6%9E%B6hugo/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Windows11安装个人博客框架hugo</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/2024-02-07-mongodb%E9%9D%A2%E8%AF%95%E9%A2%98%E9%AB%98%E7%BA%A7%E7%B1%BB/">
            <span class="next-text nav-default">MongoDB面试题[高级类]</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitalk = new Gitalk({
        id: '2024-03-04 10:31:23 \u002b0800 CST',
        title: '数据挖掘面试题',
        clientID: '3e4b82575206b75760c1',
        clientSecret: 'd3aa444dedf47396f143760cd879686e3d573191',
        repo: 'ygbingo.github.io',
        owner: 'ygbingo',
        admin: ['ygbingo'],
        body: decodeURI(location.href)
      });
      gitalk.render('gitalk-container');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/gitalk/gitalk">comments powered by gitalk.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="yanhuibin315@163.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/ygbingo" class="iconfont icon-github" title="github"></a>
  <a href="https://ygbingo.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ygbingo/hugo-theme-seven">Seven</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2019 - 
    2025<span class="heart"><i class="iconfont icon-heart"></i></span><span>YG.Bingo</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
